# -*- coding: utf-8 -*-
"""Classification Of Traffic Signs .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vzliIVOXataY2N2NZ_aD3SnoOkANYoD7
"""

from google.colab import drive
drive.mount('/content/drive')

stopFolder="/content/drive// My Drive/CNN folder/traffic signs/stop"
non_stopFolder="/content/drive// My Drive/CNN folder/traffic signs/not_stop"

import os
import csv
!pip install Pillow
from PIL import Image
!pip install pandas

csv_stopsign= "/content/drive// My Drive/CNN folder/traffic signs/stopSigns2.csv"

csv_Nonstopsign= "/content/drive// My Drive/CNN folder/traffic signs/non_stopSigns2.csv"

import os
from PIL import Image
import pandas as pd

def read_images_and_create_dataframe(folder_path, label):
    # Check if the input folder exists
    if not os.path.exists(folder_path):
        print(f"The folder '{folder_path}' does not exist.")
        return

    # Get a list of all files in the folder
    file_list = os.listdir(folder_path)

    # Filter only files with certain image extensions (e.g., '.jpg', '.jpeg', '.png', '.gif')
    image_extensions = ['.jpg', '.jpeg', '.png', '.gif']
    image_files = [file for file in file_list if any(file.lower().endswith(ext) for ext in image_extensions)]

    # Create an empty DataFrame
    df = pd.DataFrame(columns=['ImageName', 'Label'])

    # Iterate through each image, read, and append to the DataFrame
    for image_file in image_files:
        image_path = os.path.join(folder_path, image_file)

        try:
            with Image.open(image_path) as img:
                # Perform any preprocessing as needed
                # For example, you can resize the image, convert to grayscale, etc.

                # Append information to the DataFrame
                df = df.append({'ImageName': image_path, 'Label': label}, ignore_index=True)

        except Exception as e:
            print(f"Error processing image '{image_file}': {e}")

    print("Dataset created successfully. DataFrame created.")
    return df

stop_dataframe=read_images_and_create_dataframe(stopFolder,0)
not_stop_dataframe=read_images_and_create_dataframe(non_stopFolder,1)

stop_dataframe.head(5)

# Save the DataFrame to a CSV file
stop_dataframe.to_csv(csv_stopsign, index=False)

not_stop_dataframe.to_csv(csv_Nonstopsign, index=False)

from sklearn.model_selection import train_test_split

stopx_train,stopx_test, stopy_train, stopy_test=train_test_split(stop_dataframe['ImageName'],stop_dataframe['Label'], test_size=0.2, random_state=42)

Nonstopx_train,Nonstopx_test, Nonstopy_train, Nonstopy_test=train_test_split(not_stop_dataframe['ImageName'],not_stop_dataframe['Label'], test_size=0.2, random_state=42)

# Concatenate the training sets for both stop and non-stop images
train_dataframe = pd.concat([pd.DataFrame({'ImageName': stopx_train, 'Label': stopy_train}),
                             pd.DataFrame({'ImageName':Nonstopx_train , 'Label': Nonstopy_train})],
                            ignore_index=True )

test_dataframe = pd.concat([pd.DataFrame({'ImageName': stopx_test, 'Label': stopy_test}),
                             pd.DataFrame({'ImageName':Nonstopx_test , 'Label': Nonstopy_test})],
                            ignore_index=True)

# Shuffle the training DataFrame
train_dataframe = train_dataframe.sample(frac=1.0, random_state=42).reset_index(drop=True)



# Shuffle the test DataFrame
test_dataframe = test_dataframe.sample(frac=1.0, random_state=42).reset_index(drop=True)

train_dataframe.info()

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import numpy as np

def load_and_preprocess_images(image_paths, target_size=(224, 224)):
    images = []
    for path in image_paths:
        img = load_img(path, target_size=target_size)
        img_array = img_to_array(img)
        images.append(img_array)


    images= np.array(images)
    return images

# Load and preprocess the images
image_paths = train_dataframe['ImageName']
X_train = load_and_preprocess_images(image_paths)
y_train = to_categorical(train_dataframe['Label'].values)
# Load and preprocess the validation images
validation_image_paths = test_dataframe['ImageName']
X_validation = load_and_preprocess_images(validation_image_paths)
y_validation = to_categorical(test_dataframe['Label'].values)

# Define the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(2, activation='softmax'))  # Assuming 2 classes (Stop and Non-Stop)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_validation, y_validation))

# Save the trained model
model.save('/content/drive/My Drive//CNN folder/traffic signs/basemodel.h5')

# Load the VGG16 model pre-trained on ImageNet data
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Add a custom classifier on top of the VGG16 model
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(128, activation='relu')(x)
output = Dense(2, activation='softmax')(x)  # Assuming 2 classes (Stop and Non-Stop)

# Create the final model
model2 = Model(inputs=base_model.input, outputs=output)

# Compile the model
model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model2.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_validation, y_validation))

# Save the trained model
model2.save('/content/drive/My Drive//CNN folder/traffic signs/vgg16.h5')

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input

# Load the ResNet50 model pre-trained on ImageNet data
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Add a custom classifier on top of the VGG16 model
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(128, activation='relu')(x)
output = Dense(2, activation='softmax')(x)  # Assuming 2 classes (Stop and Non-Stop)

# Create the final model
model3 = Model(inputs=base_model.input, outputs=output)

# Compile the model
model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model3.fit(X_train, y_train, epochs=15, batch_size=64, validation_data=(X_validation, y_validation))

# Save the trained model
model3.save('/content/drive/My Drive//CNN folder/traffic signs/resnet50.h5')

from tensorflow.keras.preprocessing import image as keras_image
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions
import matplotlib.pyplot as plt

test_path="/content/drive/My Drive//CNN folder/traffic signs/test_set_stop_not_stop/"

image_names = ['stop_1.jpeg', 'stop_2.jpeg', 'not_stop_1.jpeg']

# Loop through the image names
for image_name in image_names:
    # Open and preprocess the image
    image_path = test_path + image_name
    img = keras_image.load_img(image_path, target_size=(224, 224))
    img_array1 = keras_image.img_to_array(img)
    img_array2 = np.expand_dims(img_array1, axis=0)
    img_array = preprocess_input(img_array2)

    # Make predictions using the model
    predictions = model2.predict(img_array)
    print(predictions)
    # Determine the predicted class based on argmax
    predicted_class = np.argmax(predictions)

    # Display the image and prediction
    prediction = "Not Stop" if predicted_class == 1 else "Stop"


    plt.imshow(img)
    plt.title(f"{image_name}: Prediction = {prediction}, Probability = {predictions[0][predicted_class]}")
    plt.show()

image_names = ['stop_1.jpeg', 'stop_2.jpeg','stop_3.jpeg', 'stop_4.jpeg', 'not_stop_1.jpeg', 'not_stop_2.jpeg', 'not_stop_3.jpeg', 'not_stop_4.jpeg', ]

# Loop through the image names
for image_name in image_names:
    # Open and preprocess the image
    image_path = test_path + image_name
    img = keras_image.load_img(image_path, target_size=(224, 224))
    img_array1 = keras_image.img_to_array(img)
    img_array2 = np.expand_dims(img_array1, axis=0)
    img_array = preprocess_input(img_array2)

    # Make predictions using the model
    predictions = model3.predict(img_array)
    print(predictions)
    # Determine the predicted class based on argmax
    predicted_class = np.argmax(predictions)

    # Display the image and prediction
    prediction = "Not Stop" if predicted_class == 1 else "Stop"


    plt.imshow(img)
    plt.title(f"{image_name}: Prediction = {prediction}, Probability = {predictions[0][predicted_class]}")
    plt.show()

image_path ="/content/drive/My Drive//CNN folder/traffic signs/test_set_stop_not_stop/stop.jpg"
    img = keras_image.load_img(image_path, target_size=(224, 224))
    img_array1 = keras_image.img_to_array(img)
    img_array2 = np.expand_dims(img_array1, axis=0)
    img_array = preprocess_input(img_array2)

    # Make predictions using the model
    predictions = model3.predict(img_array)
    print(predictions)
    # Determine the predicted class based on argmax
    predicted_class = np.argmax(predictions)

    # Display the image and prediction
    prediction = "Not Stop" if predicted_class == 1 else "Stop"


    plt.imshow(img)
    plt.title(f"image has stop sign from google: Prediction = {prediction}, Probability = {predictions[0][predicted_class]}")
    plt.show()

image_path ="/content/drive/My Drive//CNN folder/traffic signs/test_set_stop_not_stop/stoptested.jpg"
    img = keras_image.load_img(image_path, target_size=(224, 224))
    img_array1 = keras_image.img_to_array(img)
    img_array2 = np.expand_dims(img_array1, axis=0)
    img_array = preprocess_input(img_array2)

    # Make predictions using the model
    predictions = model2.predict(img_array)
    print(predictions)
    # Determine the predicted class based on argmax
    predicted_class = np.argmax(predictions)

    # Display the image and prediction
    prediction = "Not Stop" if predicted_class == 1 else "Stop"


    plt.imshow(img)
    plt.title(f"image online has stop sign: Prediction = {prediction}, Probability = {predictions[0][predicted_class]}")
    plt.show()